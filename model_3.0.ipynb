{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "history = {'loss': [59.09539031982422, 20.74762535095215, 6.167580604553223, 1.1619025468826294, 0.4605521261692047, 0.21871888637542725, 0.1192503497004509, 0.07793787121772766, 0.054312363266944885, 0.0407898835837841, 0.028131674975156784, 0.021961461752653122, 0.019648274406790733], 'accuracy': [0.20116618275642395, 0.34110787510871887, 0.5218659043312073, 0.7142857313156128, 0.8629737496376038, 0.9533527493476868, 0.9970845580101013, 0.9970845580101013, 0.9970845580101013, 0.9970845580101013, 0.9970845580101013, 1.0, 1.0], 'val_loss': [36.71835708618164, 18.216588973999023, 4.106420516967773, 1.6931058168411255, 1.2400538921356201, 1.0574349164962769, 1.0227702856063843, 0.8964598178863525, 0.9650161266326904, 0.9169053435325623, 1.0857079029083252, 0.9495127201080322, 0.9930201172828674], 'val_accuracy': [0.15662650763988495, 0.3012048304080963, 0.42168673872947693, 0.4457831382751465, 0.5783132314682007, 0.6144578456878662, 0.5662650465965271, 0.6987951993942261, 0.6385542154312134, 0.6385542154312134, 0.6385542154312134, 0.6024096608161926, 0.6265060305595398], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00020000001, 0.00020000001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi CNN + Edge + Frequent Colours\n",
    "# 69.87951993942261\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "_dataset_directory = \"drive/MyDrive/DL_PROJECT_DATASET_V1\"\n",
    "\n",
    "# Define CNN structure\n",
    "def create_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "def create_cnn_for_colors(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(input_layer)  # Using smaller kernel size\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# Create inputs for each image type\n",
    "input_original = Input(shape=(224, 224, 3))\n",
    "input_edges = Input(shape=(224, 224, 1))\n",
    "input_colors = Input(shape=(5, 3))  # Assuming 5 prominent colors\n",
    "\n",
    "# Create CNNs\n",
    "cnn_original = create_cnn((224, 224, 3))\n",
    "cnn_edges = create_cnn((224, 224, 1))\n",
    "cnn_colors = create_cnn_for_colors((5, 3, 1))  # Note: This architecture might need adjustment\n",
    "\n",
    "# Get outputs from CNNs\n",
    "output_original = cnn_original(input_original)\n",
    "output_edges = cnn_edges(input_edges)\n",
    "output_colors = cnn_colors(Lambda(lambda x: tf.expand_dims(x, axis=-1))(input_colors))\n",
    "\n",
    "# Concatenate outputs\n",
    "concatenated = Concatenate()([output_original, output_edges, output_colors])\n",
    "\n",
    "# Dense layers for classification\n",
    "dense = Dense(128, activation='relu')(concatenated)\n",
    "output_layer = Dense(6, activation='softmax')(dense)  # Assuming 6 classes\n",
    "\n",
    "# Complete model\n",
    "model = Model(inputs=[input_original, input_edges, input_colors], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def preprocess_image(img, n_colors=5):\n",
    "    # Convert from float32 to uint8 and from RGB to BGR\n",
    "    image = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Convert to grayscale for edge detection\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Edge detection\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "    resized_edges = cv2.resize(edges, (224, 224))\n",
    "\n",
    "    # Top n colors\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=0).fit(pixels)\n",
    "    prominent_colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    return resized_image, resized_edges, prominent_colors\n",
    "\n",
    "def custom_generator(image_data_generator, steps_per_epoch):\n",
    "    batch_count = 0\n",
    "    while True:\n",
    "        for batch_x, batch_y in image_data_generator:\n",
    "            batch_x_original = np.zeros((batch_x.shape[0], 224, 224, 3))\n",
    "            batch_x_edges = np.zeros((batch_x.shape[0], 224, 224, 1))\n",
    "            batch_x_colors = np.zeros((batch_x.shape[0], 5, 3))\n",
    "\n",
    "            for i, img in enumerate(batch_x):\n",
    "                original, edges, colors = preprocess_image(img)\n",
    "                batch_x_original[i] = cv2.cvtColor(original, cv2.COLOR_BGR2RGB) / 255.0\n",
    "                batch_x_edges[i] = np.expand_dims(edges, axis=-1) / 255.0\n",
    "                batch_x_colors[i] = colors / 255.0\n",
    "\n",
    "            yield [batch_x_original, batch_x_edges, batch_x_colors], batch_y\n",
    "\n",
    "            batch_count += 1\n",
    "            if batch_count >= steps_per_epoch:\n",
    "                batch_count = 0\n",
    "                break\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "total_train_samples = 343\n",
    "total_val_samples = 83\n",
    "batch_size = 32\n",
    "\n",
    "train_steps = total_train_samples // batch_size + (1 if total_train_samples % batch_size else 0)\n",
    "val_steps = total_val_samples // batch_size + (1 if total_val_samples % batch_size else 0)\n",
    "\n",
    "train_data_gen = train_datagen.flow_from_directory(\n",
    "    _dataset_directory, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='categorical', \n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data_gen = validation_datagen.flow_from_directory(\n",
    "    _dataset_directory, \n",
    "    target_size=(224, 224), \n",
    "    batch_size=batch_size, \n",
    "    class_mode='categorical', \n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "train_generator = custom_generator(train_data_gen, train_steps)\n",
    "validation_generator = custom_generator(val_data_gen, val_steps)\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model_V3.0.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# ModelCheckpoint to save the model after every epoch\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'art_style_model_best_v3.0.h5', \n",
    "    monitor='val_loss', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# EarlyStopping to stop training when the validation loss has not improved after 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau to reduce the learning rate when the validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('art_style_model_v3.0.h5')\n",
    "\n",
    "print(history.history)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
