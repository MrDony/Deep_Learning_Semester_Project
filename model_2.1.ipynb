{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Lambda, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Parameters\n",
    "n = 224  # Final image size\n",
    "m = 4    # Grid size\n",
    "grid_size = n // m\n",
    "num_cnn_layers = 3  # Number of layers in each small CNN\n",
    "num_classes = 6     # Number of art style categories\n",
    "\n",
    "_dataset_directory = \"drive/MyDrive/DL_PROJECT_DATASET_V1\"\n",
    "\n",
    "# Directory containing the dataset\n",
    "dataset_dir = _dataset_directory\n",
    "\n",
    "# Data Augmentation for training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Split data into training (80%) and validation (20%)\n",
    ")\n",
    "\n",
    "# Data generator for validation data (No augmentation, only rescaling)\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Data generator for test data (No augmentation, only rescaling)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(n, n),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(n, n),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# CNN for each grid cell\n",
    "def create_cnn(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    for _ in range(num_cnn_layers):\n",
    "        x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "        x = Conv2D(124, (2, 2), activation='relu')(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "    return Model(inputs=input_layer, outputs=x)\n",
    "\n",
    "# Input layer for the whole image\n",
    "input_layer = Input(shape=(n, n, 3))\n",
    "\n",
    "# Create CNNs for each grid cell and store their outputs\n",
    "cnn_outputs = []\n",
    "for i in range(m):\n",
    "    for j in range(m):\n",
    "        grid_input = Lambda(\n",
    "            lambda z: z[:, i*grid_size:(i+1)*grid_size, j*grid_size:(j+1)*grid_size, :]\n",
    "        )(input_layer)\n",
    "        grid_cnn = create_cnn((grid_size, grid_size, 3))\n",
    "        cnn_outputs.append(grid_cnn(grid_input))\n",
    "\n",
    "# Merge CNN outputs\n",
    "merged = Concatenate()(cnn_outputs)\n",
    "flattened = Flatten()(merged)\n",
    "\n",
    "# Final dense layers\n",
    "dense = Dense(128, activation='relu')(flattened)\n",
    "output_layer = Dense(num_classes, activation='softmax')(dense)  # Change based on your task\n",
    "\n",
    "# Complete model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model_V2.1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# ModelCheckpoint to save the model after every epoch\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'art_style_model_best_v2.1.h5',\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='max'\n",
    ")\n",
    "\n",
    "# EarlyStopping to stop training when the validation loss has not improved after 5 epochs\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ReduceLROnPlateau to reduce the learning rate when the validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('art_style_model_2.1.h5')\n",
    "\n",
    "# Evaluate the model (Optional: If you have a separate test set)\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     test_dataset_dir,\n",
    "#     target_size=(n, n),\n",
    "#     batch_size=32,\n",
    "#     class_mode='categorical'\n",
    "# )\n",
    "# model.evaluate(test_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'loss': [1.7418172359466553, 1.4547181129455566, 1.4345157146453857, 1.402978539466858, 1.3294391632080078, 1.2639915943145752, 1.2911114692687988, 1.2897870540618896, 1.2472788095474243, 1.2193827629089355, 1.1779048442840576], 'accuracy': [0.27988338470458984, 0.44897958636283875, 0.4548105001449585, 0.44606414437294006, 0.5072886347770691, 0.5218659043312073, 0.5131195187568665, 0.5102040767669678, 0.524781346321106, 0.533527672290802, 0.5160349607467651], 'val_loss': [1.5180459022521973, 1.511977195739746, 1.296093463897705, 1.3138688802719116, 1.2082133293151855, 1.2678929567337036, 1.2448573112487793, 1.2557536363601685, 1.1840312480926514, 1.1906942129135132, 1.1829643249511719], 'val_accuracy': [0.4457831382751465, 0.4337349534034729, 0.45783132314682007, 0.4819277226924896, 0.5180723071098328, 0.5421686768531799, 0.46987950801849365, 0.4939759075641632, 0.5301204919815063, 0.4939759075641632, 0.5060241222381592], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.00020000001, 0.00020000001]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
